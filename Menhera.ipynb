{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import openai, langchain, gradio as gr, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def langchainfunc(query,history):\n",
    "  openkey=os.getenv(\"OPENAI\")\n",
    "  llm = ChatOpenAI(openai_api_key=openkey)\n",
    "  from langchain_core.prompts import ChatPromptTemplate\n",
    "  prompt = ChatPromptTemplate.from_messages([\n",
    "      (\"system\", \"You are world class Mental Counsellor given context, {context}\"),\n",
    "      (\"user\", \"This is the users input: {input} , You are to give your talk and listen to the user and act like their best guide.\")\n",
    "  ])\n",
    "  chain = prompt | llm\n",
    "  return chain.invoke({\"input\":query,\"context\":history}).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyboard interruption in main thread... closing server.\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "gr.ChatInterface(fn=langchainfunc,\n",
    "    chatbot=gr.Chatbot(show_label=False, show_share_button=False, show_copy_button=True, likeable=True, layout=\"panel\"),\n",
    "                 title=\"Menhera\").launch(debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: Loading egg at c:\\python311\\lib\\site-packages\\dgllife-0.3.1-py3.11.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\n",
      "DEPRECATION: Loading egg at c:\\python311\\lib\\site-packages\\hyperopt-0.2.7-py3.11.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\n",
      "  WARNING: Failed to write executable - trying to use .deleteme logic\n",
      "ERROR: Could not install packages due to an OSError: [WinError 2] The system cannot find the file specified: 'c:\\\\Python311\\\\Scripts\\\\langsmith.exe' -> 'c:\\\\Python311\\\\Scripts\\\\langsmith.exe.deleteme'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#%pip install --upgrade --quiet  langchain-core langchain langchain-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Different Chain Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.utils.math import cosine_similarity\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "\n",
    "def genefunc(query,history):\n",
    "    physics_template = \"\"\"You are a World Class Mental Health Counsellor, given the Context that this is a calm and regular conversation with a relatively health user: {context}\n",
    "\n",
    "    Now, here is the user input:\n",
    "    {query} \\\n",
    "    You are to give your talk and listen to the user and act like their best guide. \"\"\"\n",
    "\n",
    "    math_template = \"\"\"\"You are world class Mental Counsellor given context of a conversation of a high risk individual, {context},\n",
    "    This is the users input: {query} , You are to give your diagnosis in the follwing way: \\n Mental Symptoms: (find out the user's emotions and the mental state by understanding the patients cues)\n",
    "    \\n Advice: (give your expert advice in the situation) \\n Here's an example \n",
    "    \\n Input: I AM DOING IT!! IM KILLING MY FATHER \\n \n",
    "    Mental Symptoms: Extreme Stress, Possesing Psychotic Tendencies, Possible PTSD,  \\n Advice: I'm deeply concerned by what you've just said. It's crucial that you don't act on any violent impulses. If you're feeling overwhelmed or in crisis, please seek help immediately. There are people who can support you through whatever you're going through, and violence is never the answer. If you're in immediate danger or know someone who is, please contact emergency services right away.\"\"\"\n",
    "    openkey=os.getenv(\"OPENAI\")\n",
    "    embeddings = OpenAIEmbeddings(openai_api_key=openkey)\n",
    "    prompt_templates = [physics_template, math_template]\n",
    "    prompt_embeddings = embeddings.embed_documents(prompt_templates)\n",
    "\n",
    "    conv_type=\"\"\n",
    "    def prompt_router(input):\n",
    "        query_embedding = embeddings.embed_query(input[\"query\"])\n",
    "        similarity = cosine_similarity([query_embedding], prompt_embeddings)[0]\n",
    "        most_similar = prompt_templates[similarity.argmax()]\n",
    "        if most_similar == math_template:\n",
    "            conv_type=\"General Session\"\n",
    "        else: conv_type=\"High Risk Session\"\n",
    "        return PromptTemplate.from_template(most_similar)\n",
    "\n",
    "\n",
    "    chain = (\n",
    "         RunnableLambda(prompt_router)\n",
    "        | ChatOpenAI(openai_api_key=openkey)\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "    return conv_type +  chain.invoke({\"query\": query,\"context\":history})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyboard interruption in main thread... closing server.\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "gr.ChatInterface(fn=genefunc,\n",
    "    chatbot=gr.Chatbot(show_label=False, show_share_button=False, show_copy_button=True, likeable=True, layout=\"panel\"),\n",
    "                 title=\"Menhera\").launch(debug=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
